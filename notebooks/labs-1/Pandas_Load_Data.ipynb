{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pandas](../images/pandas_logo.png)\n",
    "# Loading Data into Python with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sleepy panda](../images/panda-sleep-2.jpg)\n",
    "\n",
    "One of the fundamental concepts across Python, R, and databases is the tabular data structure, especially with named columns and records as rows.\n",
    "In Python, we use the Pandas library and the DataFrame data structure.\n",
    "In R you will learn of the native data frame type.\n",
    "In SQL, the `table` is the fundamental data storage concept.\n",
    "\n",
    "In each of these cases, there are a variety of methods to perform operations down a column of data. \n",
    "Additionally, you can subset the data by selecting a list of columns and filtering out others to only have particular rows based on boolean (T/F) tests of conditions.\n",
    "Even more concepts are possible, as you will see, such as grouping rows for analytics and other operations.\n",
    "\n",
    "Python has an extensive set of libraries that make it easier to manipulate data. \n",
    "**Pandas** is one such package that is shown here and used extensively within this course. \n",
    "This notebook illustrates the basics of reading a file into a **Panda dataframe**. \n",
    "Not only does `Pandas` assist in data loading, but the _data frame_ concept is the preferred structure of data for numerous compuational libraries that are part of the extensive Python ecosystem.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a csv file using Pandas. \n",
    "\n",
    "----\n",
    "\n",
    "**Reference: **[Loading a CSV into Pandas](http://chrisalbon.com/python/pandas_dataframe_importing_csv.html)\n",
    "\n",
    "\n",
    "** There are two ways of reading a Comma Separated Variables (CSV) file into a dataframe: **\n",
    "\n",
    "* pd.read_csv(path, index_col=0, parse_dates=True)\n",
    "\n",
    "* pd.DataFrame.from_csv(path)\n",
    "\n",
    "#### Method 1\n",
    "The first one is the preferred way of reading a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('/dsa/data/all_datasets/auto-mpg/auto-mpg.csv', 'r') as file:\n",
    "    df1 = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's that simple! <br><br>\n",
    "\n",
    "The simple code block above does three things:\n",
    "\n",
    " 1. Load the `pandas` library giving it an alias name of `pd`.\n",
    " 2. Opens the file `/dsa/data/all_datasets/auto-mpg/auto-mpg.csv`.\n",
    "    * This file is located from the root of the file system, then down each folder after a \"/\" and finally down into the `auto-mpg/` folder\n",
    "    * The open file is then referred to as the variable `file`\n",
    " 3. The data is then read \n",
    "    1. Using the pandas library, \n",
    "    1. Interpretted as a CSV formatted file, and\n",
    "    1. Stored as a `DataFrame` in a variable named `df1`\n",
    "\n",
    "Actually, it can be even simpler. Running the one-line of code below would produce the same result. \n",
    "\n",
    "```python\n",
    "pd.read_csv('/dsa/data/all_datasets/auto-mpg/auto-mpg.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's see what the _df1_ `DataFrame` looks like ... **\n",
    "\n",
    "\n",
    "The _head()_ function will display first 5 rows of data that gives an overview of what kind of data each column holds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment after the '#'\n",
    "\n",
    "df1.head()   # the head method/function/command on the DataFrame variable previews the first 5 rows\n",
    "\n",
    "# Optionally df.head(10) would show 10 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.tail()  # the tail method/function/command on the DataFrame variable previews the last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "\n",
    "Read the data using **pd.DataFrame.from_csv()**\n",
    "\n",
    "\n",
    "**Syntax:** \n",
    "\n",
    "pandas.DataFrame.from_csv(path, header=0, sep=', ', index_col=0, parse_dates=True, encoding=None, tupleize_cols=False, infer_datetime_format=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=pd.DataFrame.from_csv('../../../datasets/auto-mpg/auto-mpg.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that **pd.DataFrame.from_csv()** differs from **pandas.read_csv()** for some of the default conditions:\n",
    "\n",
    "- We have to specify `index_col=None` to ensure the first column is treated as data and not a row index.\n",
    "- Additionally, data files with dates will be treated differently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Using `read_csv()` for non-CSV files\n",
    "\n",
    "`pandas.read_csv()` can also be used for reading data from a other types of text files into pandas dataframe.\n",
    "In this example, we are loading a file that is _white space separated_ instead of _comma separated_.\n",
    "_White space_ includes space characters, tab characters, and a few other special characters that do not normally render as text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we add the addition sep function argument\n",
    "\n",
    "text_df = pd.read_csv(\"/dsa/data/all_datasets/auto-mpg/auto-mpg.txt\", sep='\\s+')  # \\s+ denotes the data delimeter to be white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "### Subsetting Data\n",
    "\n",
    "Once data is into panda DataFrame, we can filter the data based on columns headings and values within rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('/dsa/data/all_datasets/auto-mpg/auto-mpg.csv', 'r') as file:\n",
    "    cars = pd.read_csv(file)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Columns\n",
    "\n",
    "Selecting columns is accomplished using the `[]` brackets.\n",
    " 1. Selecting one column is accomplished by listing the desired column name, e.g., `['car name']`\n",
    " 1. Selecting more than one column is done by passing a list of columns into the `[]` brackets.\n",
    "    * For example:\n",
    "```\n",
    "cars[\n",
    "        ['cylinders','car name']\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = cars['car name']\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cylinders_and_name = cars[['cylinders','car name']]\n",
    "cylinders_and_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Rows\n",
    "\n",
    "Recall from the NumPy lesson the selection of rows.\n",
    "Row selection is similar in Pandas where you test a value within a column.\n",
    "The test will generate a list of `True` and `False` values for each row, which then selects the appropriate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for cylinders column = to 5\n",
    "#  Note '==' is used because a single '=' is used for assignment\n",
    "\n",
    "five_cylinders = cars[ cars['cylinders']==5 ]\n",
    "five_cylinders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Row and Column selection\n",
    "\n",
    "A Data Frame can be filtered using column selection and row value filter:\n",
    "  1. First filter the rows using a column test against the original DataFrame\n",
    "  1. Next specify the desired subset of columns\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_five_cyl = cars[ cars['cylinders']==5 ][['mpg','cylinders','displacement','car name']]\n",
    "small_five_cyl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, this order of operations can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_five_cyl_2 = cars[['mpg','cylinders','displacement','car name']][ cars['cylinders']==5 ]\n",
    "small_five_cyl_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Operations\n",
    "\n",
    "Under the hood `Pandas` uses `NumPy` for storage of data.\n",
    "As such, we are able to do the same mathematical operations on columns as we did on `NumPy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('/dsa/data/all_datasets/auto-mpg/auto-mpg.csv', 'r') as file:\n",
    "    cars = pd.read_csv(file)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `Pandas` and `NumPy` allow you to convert the type of a column to another type.\n",
    "The `dtype:` describes the data type.\n",
    "In the case of the `weight` column, the data is a 64-bit integer (whole number).\n",
    "```\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the type of the weight column\n",
    "\n",
    "cars['weight'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign the whole weight column to a new column of the desired data type\n",
    "\n",
    "cars['weight'] = cars['weight'].astype(float)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the new type of the weight column\n",
    "\n",
    "cars['weight'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily perform basic math on the columns, such as converting the weight column from pounds to tons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['weight'] = cars['weight'] / 2000.0\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding and Removing Columns\n",
    "\n",
    "Columns can be added and removed as well.\n",
    "\n",
    "Columns are added by simply specifying a new column name and setting it to a series of values of the appropriate length.\n",
    "\n",
    "Columns are removed by using the Python `del` command and the column reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(start, end) produces the list of values from 'start' through 'end'-1\n",
    "# len(cars) determines the length of the cars column, i.e the number of rows\n",
    "# Then add one to get the last row number\n",
    "\n",
    "cars['rowNumber'] = range(1,len(cars)+1)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cars['origin']\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been just a brief introduction to pandas DataFrames. \n",
    "You will see these used continuously throughout the course for loading data, then providing input to statistical and visualization functionality of Python libraries.\n",
    "\n",
    "# SAVE YOUR NOTEBOOK!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
